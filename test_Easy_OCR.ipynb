{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'easyocr'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01measyocr\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mutil\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'easyocr'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import easyocr\n",
    "import util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define constants for model and data paths\n",
    "# These paths point to the configuration file, weights file, class names file, and input directory.\n",
    "# Path to YOLO model configuration file\n",
    "\n",
    "model_cfg_path = os.path.join('.', 'model', 'cfg', 'darknet-yolov3.cfg')\n",
    "\n",
    "# Path to YOLO model weights file\n",
    "model_weights_path = os.path.join('.', 'model', 'weights', 'model.weights')\n",
    "\n",
    "# Path to file containing class names used by the model\n",
    "class_names_path = os.path.join('.', 'model', 'class.names')\n",
    "\n",
    "# Directory containing input images for license plate detection\n",
    "input_dir = r'D:\\PycharmProjects\\license_plate_detection\\data'\n",
    "# Ensure to replace this path with the actual path to your dataset or input images.\n",
    "\n",
    "# These paths are used to load the YOLO model and necessary files, as well as specify the input directory.\n",
    "# Ensure that the directory structure and file names match the actual structure and names in your project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = cv2.dnn.readNetFromDarknet(model_cfg_path, model_weights_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'easyocr' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m reader \u001b[38;5;241m=\u001b[39m \u001b[43measyocr\u001b[49m\u001b[38;5;241m.\u001b[39mReader([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124men\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# Iterate through each image in the input directory\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m img_name \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39mlistdir(input_dir):\n\u001b[0;32m      4\u001b[0m \n\u001b[0;32m      5\u001b[0m     \u001b[38;5;66;03m# Construct full path to the image\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'easyocr' is not defined"
     ]
    }
   ],
   "source": [
    "reader = easyocr.Reader(['en'])\n",
    "# Iterate through each image in the input directory\n",
    "for img_name in os.listdir(input_dir):\n",
    "\n",
    "    # Construct full path to the image\n",
    "    img_path = os.path.join(input_dir, img_name)\n",
    "\n",
    "    # Load class names from the file\n",
    "    with open(class_names_path, 'r') as f:\n",
    "        class_names = [j[:-1] for j in f.readlines() if len(j) > 2]\n",
    "        f.close()\n",
    "\n",
    "    # Load the image\n",
    "    img = cv2.imread(img_path)\n",
    "\n",
    "    # Check if the image is successfully loaded\n",
    "    if img is None:\n",
    "        print(f\"Error: Unable to read image\")\n",
    "    else:\n",
    "        # Get image dimensions\n",
    "        H, W, _ = img.shape\n",
    "        # Continue with the rest of the code\n",
    "\n",
    "    # Convert the image to a format suitable for YOLO model\n",
    "    blob = cv2.dnn.blobFromImage(img, 1 / 255, (416, 416), (0, 0, 0), True)\n",
    "\n",
    "    # Get YOLO model detections\n",
    "    net.setInput(blob)\n",
    "    detections = util.get_outputs(net)\n",
    "\n",
    "    # Lists to store bounding boxes, class IDs, and scores\n",
    "    bboxes = []\n",
    "    class_ids = []\n",
    "    scores = []\n",
    "\n",
    "    # Process each detection\n",
    "    for detection in detections:\n",
    "        # Extract coordinates of the bounding box\n",
    "        bbox = detection[:4]\n",
    "        xc, yc, w, h = bbox\n",
    "        bbox = [int(xc * W), int(yc * H), int(w * W), int(h * H)]\n",
    "\n",
    "        # Extract confidence score and class ID\n",
    "        bbox_confidence = detection[4]\n",
    "        class_id = np.argmax(detection[5:])\n",
    "        score = np.amax(detection[5:])\n",
    "\n",
    "        # Append to lists\n",
    "        bboxes.append(bbox)\n",
    "        class_ids.append(class_id)\n",
    "        scores.append(score)\n",
    "\n",
    "    # Apply Non-Maximum Suppression (NMS) to filter overlapping bounding boxes\n",
    "    bboxes, class_ids, scores = util.NMS(bboxes, class_ids, scores)\n",
    "\n",
    "\n",
    "    # Process each detected bounding box\n",
    "    for bbox_, bbox in enumerate(bboxes):\n",
    "        xc, yc, w, h = bbox\n",
    "\n",
    "        # Extract the license plate region from the image\n",
    "        license_plate = img[int(yc - (h / 2)):int(yc + (h / 2)), int(xc - (w / 2)):int(xc + (w / 2)), :].copy()\n",
    "\n",
    "        # Draw a rectangle around the detected license plate on the original image\n",
    "        img = cv2.rectangle(img,\n",
    "                            (int(xc - (w / 2)), int(yc - (h / 2))),\n",
    "                            (int(xc + (w / 2)), int(yc + (h / 2))),\n",
    "                            (0, 255, 0), 15)\n",
    "\n",
    "        # Convert the license plate region to grayscale\n",
    "        license_plate_gray = cv2.cvtColor(license_plate, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Threshold the license plate image\n",
    "        _, license_plate_thresh = cv2.threshold(license_plate_gray, 64, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "        # Perform OCR on the thresholded license plate image\n",
    "        output = reader.readtext(license_plate_thresh)\n",
    "\n",
    "        license_plate_texts = []\n",
    "        Avg_score = []\n",
    "\n",
    "        # Process each OCR output\n",
    "        for out in output:\n",
    "            text_bbox, text, text_score = out\n",
    "            if text_score > 0.2:\n",
    "                license_plate_texts.append(text)\n",
    "                Avg_score.append(text_score)\n",
    "        print(img_path,(' ').join(license_plate_texts), np.mean(Avg_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'ultralytics'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m transforms\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01multralytics\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Define constants for model and data paths\u001b[39;00m\n\u001b[0;32m     11\u001b[0m model_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mD:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mPycharmProjects\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mlicense_plate_detection\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mmodel_- 12 january 2024 14_47.pt\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'ultralytics'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import easyocr\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "import ultralytics\n",
    "\n",
    "# Define constants for model and data paths\n",
    "model_path = r'D:\\PycharmProjects\\license_plate_detection\\model_- 12 january 2024 14_47.pt'\n",
    "input_dir = r'D:\\PycharmProjects\\license_plate_detection\\data'\n",
    "\n",
    "# List to store detected license plate texts\n",
    "license_plate_texts = []\n",
    "\n",
    "\n",
    "\n",
    "# Load your new license plate detection model\n",
    "new_model = torch.load(model_path)\n",
    "new_model.eval()\n",
    "\n",
    "# Initialize EasyOCR reader for English language\n",
    "reader = easyocr.Reader(['en'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data': [], 'message': 'Inference complete.', 'success': True}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# API URL, use actual MODEL_ID\n",
    "url = f\"https://api.ultralytics.com/v1/predict/kzp4sRWJYJKkgvPkeX70\"\n",
    "\n",
    "# Headers, use actual API_KEY\n",
    "headers = {\"x-api-key\": \"2386d451088da58c8638f6d14020fc3d1bbab835c0\"}\n",
    "\n",
    "# Inference arguments (optional)\n",
    "data = {\"size\": 640, \"confidence\": 0.25, \"iou\": 0.45}\n",
    "\n",
    "# Load image and send request\n",
    "with open(\"D:\\PycharmProjects\\license_plate_detection\\data1\\Cars348.png\", \"rb\") as image_file:\n",
    "    files = {\"image\": image_file}\n",
    "    response = requests.post(url, headers=headers, files=files, data=data)\n",
    "\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'ultralytics'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01multralytics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m YOLO\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Load model\u001b[39;00m\n\u001b[0;32m      4\u001b[0m model \u001b[38;5;241m=\u001b[39m YOLO(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124myolov8s.pt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'ultralytics'"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load model\n",
    "model = YOLO('yolov8s.pt')\n",
    "\n",
    "# Run inference\n",
    "results = model('image.jpg')\n",
    "\n",
    "# Print image.jpg results in JSON format\n",
    "print(results[0].tojson())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
